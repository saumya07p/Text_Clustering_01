{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "bzGM8QXmYpeJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "Y_4OkyLuViKu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categories = [\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'alt.atheism',\n",
        " 'soc.religion.christian',\n",
        "]\n",
        "dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True)"
      ],
      "metadata": {
        "id": "wpySoCOLVlyO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset.data, columns=[\"corpus\"])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiaJa2JAVvdP",
        "outputId": "8b3c870c-dc72-4cda-a0dd-a14c9a5154c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 corpus\n",
            "0     From: ferguson@cs.rochester.edu (George Fergus...\n",
            "1     From: roger@crux.Princeton.EDU (Roger Lustig)\\...\n",
            "2     From: johnsd2@rpi.edu (Dan Johnson)\\nSubject: ...\n",
            "3     From: tdawson@engin.umich.edu (Chris Herringsh...\n",
            "4     From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: te...\n",
            "...                                                 ...\n",
            "3446  From: bobbe@vice.ICO.TEK.COM (Robert Beauchain...\n",
            "3447  From: galvint@cs.nps.navy.mil (thomas galvin)\\...\n",
            "3448  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\\n...\n",
            "3449  From: khettry@r1w2.pub.utk.edu (23064RFL)\\nSub...\n",
            "3450  From: cs902043@ariel.yorku.ca (SHAWN LUDDINGTO...\n",
            "\n",
            "[3451 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "_pz9cSS1DRdv",
        "outputId": "326b5023-1254-464a-ee35-cb664f556247"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   corpus\n",
              "count                                                3451\n",
              "unique                                               3451\n",
              "top     From: ferguson@cs.rochester.edu (George Fergus...\n",
              "freq                                                    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beef765a-b4c0-49e4-b8b9-20628b8cf9ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>From: ferguson@cs.rochester.edu (George Fergus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beef765a-b4c0-49e4-b8b9-20628b8cf9ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-beef765a-b4c0-49e4-b8b9-20628b8cf9ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-beef765a-b4c0-49e4-b8b9-20628b8cf9ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEP9zEnnV3zX",
        "outputId": "3a9ba686-af04-4818-bdb8-bc282db065a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsr2tgVMWFOJ",
        "outputId": "e4070427-203d-4b0b-8d05-d3e892d3f2ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n",
        "    if remove_stopwords:\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        tokens = [w for w in tokens if not w.lower() in stopwords.words(\"english\")]\n",
        "        text = \" \".join(tokens)\n",
        "    text = text.lower().strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "oehsNwifWJ2S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3cAWxUFWcEV",
        "outputId": "222b8c00-574a-48d5-9e4a-662a49b4afd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned'] = df['corpus'].apply(lambda x: preprocess_text(x, remove_stopwords=True))\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jxYB7b0WfS1",
        "outputId": "8e648a33-000d-49dd-ac10-82e0040c7541"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 corpus  \\\n",
            "0     From: ferguson@cs.rochester.edu (George Fergus...   \n",
            "1     From: roger@crux.Princeton.EDU (Roger Lustig)\\...   \n",
            "2     From: johnsd2@rpi.edu (Dan Johnson)\\nSubject: ...   \n",
            "3     From: tdawson@engin.umich.edu (Chris Herringsh...   \n",
            "4     From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: te...   \n",
            "...                                                 ...   \n",
            "3446  From: bobbe@vice.ICO.TEK.COM (Robert Beauchain...   \n",
            "3447  From: galvint@cs.nps.navy.mil (thomas galvin)\\...   \n",
            "3448  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\\n...   \n",
            "3449  From: khettry@r1w2.pub.utk.edu (23064RFL)\\nSub...   \n",
            "3450  From: cs902043@ariel.yorku.ca (SHAWN LUDDINGTO...   \n",
            "\n",
            "                                                cleaned  \n",
            "0     ferguson cs rochester edu george ferguson subj...  \n",
            "1     roger crux princeton edu roger lustig subject ...  \n",
            "2     johnsd rpi edu dan johnson subject accepting j...  \n",
            "3     tdawson engin umich edu chris herringshaw subj...  \n",
            "4     situnaya ibm bham ac uk subject test sorry org...  \n",
            "...                                                 ...  \n",
            "3446  bobbe vice ico tek com robert beauchaine subje...  \n",
            "3447  galvint cs nps navy mil thomas galvin subject ...  \n",
            "3448  tmc spartan ac brocku ca tim ciceran subject m...  \n",
            "3449  khettry r w pub utk edu rfl subject testing or...  \n",
            "3450  cs ariel yorku ca shawn luddington subject jac...  \n",
            "\n",
            "[3451 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.95)\n",
        "X = vectorizer.fit_transform(df['cleaned'])"
      ],
      "metadata": {
        "id": "910_hj5EXdxJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "clusters = kmeans.labels_"
      ],
      "metadata": {
        "id": "FtGoUZabXitu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "pca_vecs = pca.fit_transform(X.toarray())\n",
        "x0 = pca_vecs[:, 0]\n",
        "x1 = pca_vecs[:, 1]"
      ],
      "metadata": {
        "id": "W1pqZaqQXrBk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'] = clusters\n",
        "df['x0'] = x0\n",
        "df['x1'] = x1\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzdqJjFAXyuw",
        "outputId": "033d0943-ea75-4c0b-c7ba-4dc8afa841c2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 corpus  \\\n",
            "0     From: ferguson@cs.rochester.edu (George Fergus...   \n",
            "1     From: roger@crux.Princeton.EDU (Roger Lustig)\\...   \n",
            "2     From: johnsd2@rpi.edu (Dan Johnson)\\nSubject: ...   \n",
            "3     From: tdawson@engin.umich.edu (Chris Herringsh...   \n",
            "4     From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: te...   \n",
            "...                                                 ...   \n",
            "3446  From: bobbe@vice.ICO.TEK.COM (Robert Beauchain...   \n",
            "3447  From: galvint@cs.nps.navy.mil (thomas galvin)\\...   \n",
            "3448  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\\n...   \n",
            "3449  From: khettry@r1w2.pub.utk.edu (23064RFL)\\nSub...   \n",
            "3450  From: cs902043@ariel.yorku.ca (SHAWN LUDDINGTO...   \n",
            "\n",
            "                                                cleaned  cluster        x0  \\\n",
            "0     ferguson cs rochester edu george ferguson subj...        2 -0.040863   \n",
            "1     roger crux princeton edu roger lustig subject ...        2 -0.006483   \n",
            "2     johnsd rpi edu dan johnson subject accepting j...        0  0.100123   \n",
            "3     tdawson engin umich edu chris herringshaw subj...        1 -0.114083   \n",
            "4     situnaya ibm bham ac uk subject test sorry org...        1 -0.079734   \n",
            "...                                                 ...      ...       ...   \n",
            "3446  bobbe vice ico tek com robert beauchaine subje...        0  0.076584   \n",
            "3447  galvint cs nps navy mil thomas galvin subject ...        2 -0.042541   \n",
            "3448  tmc spartan ac brocku ca tim ciceran subject m...        1 -0.124643   \n",
            "3449  khettry r w pub utk edu rfl subject testing or...        1 -0.081430   \n",
            "3450  cs ariel yorku ca shawn luddington subject jac...        2 -0.004287   \n",
            "\n",
            "            x1  \n",
            "0     0.114957  \n",
            "1     0.062905  \n",
            "2    -0.038591  \n",
            "3    -0.083837  \n",
            "4    -0.068972  \n",
            "...        ...  \n",
            "3446 -0.068306  \n",
            "3447  0.160873  \n",
            "3448 -0.088971  \n",
            "3449 -0.014424  \n",
            "3450  0.161598  \n",
            "\n",
            "[3451 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_keywords(n_terms):\n",
        "    df = pd.DataFrame(X.todense()).groupby(clusters).mean()\n",
        "    terms = vectorizer.get_feature_names_out() \n",
        "    for i,r in df.iterrows():\n",
        "        print('\\nCluster {}'.format(i))\n",
        "        print(','.join([terms[t] for t in np.argsort(r)[-n_terms:]])) \n",
        "            \n",
        "get_top_keywords(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yerzTRERYChu",
        "outputId": "16801f09-96eb-4b7c-873b-c3a1453b9d52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster 0\n",
            "say,think,jesus,writes,com,would,one,people,edu,god\n",
            "\n",
            "Cluster 1\n",
            "nntp,host,posting,file,graphics,university,thanks,com,edu,windows\n",
            "\n",
            "Cluster 2\n",
            "baseball,players,university,writes,article,year,ca,game,team,edu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_map = {0: \"1\", 1: \"2\", 2: \"3\"}                          \n",
        "df['cluster'] = df['cluster'].map(cluster_map)"
      ],
      "metadata": {
        "id": "ET9X8_K9Yd9u"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}